python core/run_seq2seq.py --model_name_or_path 't5-base' --do_train --task translation_src_to_tgt --train_file data/en_RC_PP_sm-nodist-pres-and-past/en_RC_PP_sm-nodist-pres-and-past_train.json.gz --validation_file data/en_RC_PP_sm-nodist-pres-and-past/en_RC_PP_sm-nodist-pres-and-past_dev.json.gz --output_dir outputs/t5-base-finetuning-en_RC_PP_sm-nodist-pres-and-past-bs128/ --per_device_train_batch_size=4 --gradient_accumulation_steps=32 --per_device_eval_batch_size=16 --overwrite_output_dir --predict_with_generate --num_train_epochs 10.0
